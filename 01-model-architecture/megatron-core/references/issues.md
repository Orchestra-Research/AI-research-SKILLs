# GitHub Issues

Recent issues from the repository (7 total).

## Open Issues (5)

### #2163: Embeddings / output parameter sharding with LayerWiseOptimizer (dist_muon)
**Labels:** enhancement | **Created:** 2025-11-06
[View on GitHub](https://github.com/NVIDIA/Megatron-LM/issues/2163)

### #2156: [QUESTION] AssertionError: decoupled_learning_rate is None during logging (Llama 3 8B, PP=4, Megatron-core v0.14.0)
**Labels:** bug | **Created:** 2025-11-06
[View on GitHub](https://github.com/NVIDIA/Megatron-LM/issues/2156)

### #2063: [QUESTION] Enabling `--fp8-param-gather` during model training with `mxfp8` consumes more GPU memory compared to leaving it disabled.
**Labels:** question, module: transformer engine | **Created:** 2025-10-31
[View on GitHub](https://github.com/NVIDIA/Megatron-LM/issues/2063)

### #1729: [ROADMAP][Updated on November 4] Megatron Core MoE Q3-Q4 2025 Roadmap
**Labels:** module: moe, call for contribution, dev branch | **Created:** 2025-08-04
[View on GitHub](https://github.com/NVIDIA/Megatron-LM/issues/1729)

### #1921: Megatron Supports InternVL OR NOT?
**Labels:** enhancement | **Created:** 2025-10-24
[View on GitHub](https://github.com/NVIDIA/Megatron-LM/issues/1921)


## Recently Closed Issues (2)

### #2162: balanced layerwise sharding with dist_muon
**Labels:** enhancement | **Closed:** 2025-11-06
[View on GitHub](https://github.com/NVIDIA/Megatron-LM/issues/2162)

### #2146: Qwen3 Omni训练加载lora权重失败
**Labels:** bug | **Closed:** 2025-11-06
[View on GitHub](https://github.com/NVIDIA/Megatron-LM/issues/2146)

