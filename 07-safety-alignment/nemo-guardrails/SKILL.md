# Guardrails

Expert guidance for LLM safety with NeMo Guardrails

## Description

NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems.

**Repository:** [NVIDIA-NeMo/Guardrails](https://github.com/NVIDIA-NeMo/Guardrails)
**Language:** Python
**Stars:** 5,231
**License:** Other

## When to Use This Skill

Use this skill when you need to:
- Understand how to use nemo-guardrails
- Look up API documentation
- Find usage examples
- Check for known issues or recent changes
- Review release history

## Quick Reference

### Repository Info
- **Homepage:** https://docs.nvidia.com/nemo/guardrails/latest/index.html
- **Topics:** agents, guardrails, python, safety, generative-ai, llms, nvidia, llm-safety, llm-security
- **Open Issues:** 170
- **Last Updated:** 2025-11-06

### Languages
- **Python:** 99.6%
- **Dockerfile:** 0.1%
- **HTML:** 0.1%
- **YARA:** 0.1%
- **Makefile:** 0.0%
- **JavaScript:** 0.0%

### Recent Releases
- **v0.18.0** (2025-11-06): 
- **v0.17.0** (2025-10-09): v0.17.0
- **v0.16.0** (2025-09-05): v0.16.0

## Available References

- `references/README.md` - Complete README documentation
- `references/CHANGELOG.md` - Version history and changes
- `references/issues.md` - Recent GitHub issues
- `references/releases.md` - Release notes
- `references/file_structure.md` - Repository structure

## Usage

See README.md for complete usage instructions and examples.

---

**Generated by Skill Seeker** | GitHub Repository Scraper
