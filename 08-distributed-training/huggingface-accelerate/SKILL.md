# accelerate

Expert guidance for Accelerate - distributed training simplified

## Description

ðŸš€ A simple way to launch, train, and use PyTorch models on almost any device and distributed configuration, automatic mixed precision (including fp8), and easy-to-configure FSDP and DeepSpeed support

**Repository:** [huggingface/accelerate](https://github.com/huggingface/accelerate)
**Language:** Python
**Stars:** 9,266
**License:** Apache License 2.0

## When to Use This Skill

Use this skill when you need to:
- Understand how to use huggingface-accelerate
- Look up API documentation
- Find usage examples
- Check for known issues or recent changes
- Review release history

## Quick Reference

### Repository Info
- **Homepage:** https://huggingface.co/docs/accelerate
- **Topics:** 
- **Open Issues:** 108
- **Last Updated:** 2025-11-06

### Languages
- **Python:** 99.6%
- **Dockerfile:** 0.2%
- **Makefile:** 0.2%
- **Shell:** 0.0%

### Recent Releases
- **v1.11.0** (2025-10-20): v1.11.0: TE MXFP8, FP16/BF16 with MPS, Python 3.10 
- **v1.10.1** (2025-08-25): v1.10.1: Patchfix
- **v1.10.0** (2025-08-07): v1.10.0: N-D Parallelism

## Available References

- `references/README.md` - Complete README documentation
- `references/CHANGELOG.md` - Version history and changes
- `references/issues.md` - Recent GitHub issues
- `references/releases.md` - Release notes
- `references/file_structure.md` - Repository structure

## Usage

See README.md for complete usage instructions and examples.

---

**Generated by Skill Seeker** | GitHub Repository Scraper
